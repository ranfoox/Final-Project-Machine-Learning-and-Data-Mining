# Final-Project-Machine-Learning-and-Data-Mining-

#Dataset: Heart
The Heart dataset seems to focus on cardiovascular health, featuring variables like age, gender, blood pressure, and cholesterol levels. It likely serves to analyze the relationships between these factors and heart-related conditions for predictive or diagnostic purposes.

#Abstract:
This project delves into the analysis of the Heart dataset, aiming to comprehend its underlying structure, patterns, and predictive potential. The investigation encompasses various stages, including exploratory data analysis, clustering, supervised learning, and dimensionality reduction techniques. Through these analyses, we aim to gain insights into the dataset's characteristics, identify potential clusters or patterns, build predictive models, and explore methods for reducing the dataset's dimensionality while preserving essential information. The findings and conclusions drawn from this analysis contribute to a better understanding of the dataset and its potential applications in healthcare and predictive modeling.

#Exploratory Data Analysis (EDA):
The exploratory data analysis (EDA) phase begins with a thorough examination of the Heart dataset, encompassing an assessment of its shape, types of features and examination for missing values . Following this initial step, the focus shifts to understanding the distribution, relationships between variables, and potential outliers within the dataset. Key statistics such as mean, median, standard deviation, and correlation coefficients are computed to provide a concise overview of the dataset's characteristics. Utilizing visualizations such as box plots, scatter plots, and correlation matrices, we aim to unravel the underlying structure of the data and identify any discernible patterns or anomalies. Additionally, feature selection techniques are employed to pinpoint the most relevant variables for modeling, while outlier detection methods ensure data quality and enhance model robustness.

#Data Preparation:
In this phase, we undertake several essential steps to prepare the Heart dataset for modeling. First, we identify and remove one of each pair of highly correlated features to prevent redundancy. Next, we apply one-hot encoding to categorical variables to transform them into a numerical format suitable for machine learning algorithms. Additionally, we perform min-max normalization to scale the feature values within a specific range, ensuring consistency and aiding convergence during model training. These preprocessing steps are crucial to optimize the performance of our models and facilitate meaningful insights from the data.
Unsupervised Learning

#Clustering:
At the onset of this phase, we generated a visual representation of the dendrogram to aid in the analysis and determination of the optimal number of clusters. Additionally, a new column called "cluster" was added to the dataset to facilitate clustering. Utilizing hierarchical clustering, we identified inherent groupings or clusters within the dataset. By grouping similar observations together, clustering facilitates the discovery of underlying patterns or relationships in the data. The resultant clusters are examined through the presentation of centroids and a detailed description of features within each cluster, aiding in the understanding of their characteristics and potential implications in healthcare or predictive modeling tasks.

Supervised Learning: In this phase, supervised learning algorithms, random forests, are employed to construct predictive models for heart-related outcomes, to predicting the "Reaction" variable. The dataset is partitioned into training and testing sets, and various performance metrics including accuracy, precision, recall, and F1 score are utilized to assess model performance. Additionally, we conducted an analysis to evaluate the importance and contribution of the unsupervised learning-derived clusters on the supervised model. To accomplish this, we trained the model both with and without the cluster column, drawing comparisons and insights from the results aided by visualizations.

#Dimensionality Reduction:
We explored dimensionality reduction techniques, principal component analysis (PCA), to reduce the dataset's dimensionality while preserving essential information. After conducting numerous variation tests with different data preprocessing and selection options, including testing with two and three dimensions, it was concluded that the dataset is not suitable for PCA analysis. This decision was made due to the unsatisfactory retention of information, indicating that PCA may not effectively capture the dataset's underlying structure.


#Conclusions:
The analysis of the Heart dataset has yielded valuable insights into its structure, patterns, and predictive potential. Through exploratory data analysis, significant relationships and trends within the data were uncovered, while clustering techniques provided insights into natural groupings or clusters. Supervised learning models showed promising performance in predicting heart-related outcomes. Additionally, attempts at dimensionality reduction, while unsuccessful, provided further understanding of the data's complexity. Overall, this analysis enhances our understanding of the dataset and its potential applications in healthcare and predictive modeling tasks.
